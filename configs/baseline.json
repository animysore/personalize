{
  "model": {
    "name": "meta-llama/Llama-3.2-1B-Instruct",
    "device": "auto",
    "torch_dtype": "float16",
    "max_context_tokens": 512
  },
  "generation": {
    "max_new_tokens": 256,
    "temperature": 0.7,
    "top_p": 0.9,
    "do_sample": true
  },
  "context_template": "### User Context\n{context}\n\n### Instruction\n{prompt}\n\n### Response\n",
  "no_context_template": "### Instruction\n{prompt}\n\n### Response\n"
}
